{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ccede7e",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/main/projects/ECoG/load_ECoG_joystick_track.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content/main/projects/ECoG/load_ECoG_joystick_track.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bcda88",
   "metadata": {},
   "source": [
    "## Loading of Miller ECoG data of the joystick track task\n",
    "\n",
    "includes some visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ba5229",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "#@title Data retrieval\n",
    "import os, requests\n",
    "\n",
    "fname = 'joystick_track.npz'\n",
    "url = \"https://osf.io/6jncm/download\"\n",
    "\n",
    "if not os.path.isfile(fname):\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except requests.ConnectionError:\n",
    "        print(\"!!! Failed to download data !!!\")\n",
    "    else:\n",
    "        if r.status_code != requests.codes.ok:\n",
    "            print(\"!!! Failed to download data !!!\")\n",
    "        else:\n",
    "            with open(fname, \"wb\") as fid:\n",
    "                fid.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406edbb0",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Install packages (`nilearn`, `nimare`. `duecredit`), import `matplotlib` and set defaults\n",
    "# install packages to visualize brains and electrode locations\n",
    "!pip install nilearn --quiet\n",
    "!pip install nimare --quiet\n",
    "!pip install duecredit --quiet\n",
    "\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "rcParams['figure.figsize'] = [20, 4]\n",
    "rcParams['font.size'] = 15\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['figure.autolayout'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a151e79",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Data loading\n",
    "import numpy as np\n",
    "\n",
    "alldat = np.load(fname, allow_pickle=True)['dat']\n",
    "\n",
    "# Select just one of the recordings here. This is subject 1, block 1.\n",
    "dat = alldat[0][0]\n",
    "\n",
    "print(dat.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f81ad37",
   "metadata": {},
   "source": [
    "# Dataset info #\n",
    "\n",
    "This is one of multiple ECoG datasets from Miller 2019, recorded in clinical settings with a variety of tasks. Raw data here:\n",
    "\n",
    "https://exhibits.stanford.edu/data/catalog/zk881ps0522\n",
    "\n",
    "`dat` contain 4 sessions from 4 subjects, and was used in these papers:\n",
    "\n",
    "- Schalk, G., et al. \"Decoding two-dimensional movement trajectories using electrocorticographic signals in humans.\" Journal of Neural Engineering 4.3 (2007): 264. doi: [10.1088/1741-2560/4/3/012](https://doi.org/10.1088/1741-2560/4/3/012)\n",
    "\n",
    "- Schalk, Gerwin, et al. \"Two-dimensional movement control using electrocorticographic signals in humans.\" Journal of Neural Engineering 5.1 (2008): 75. doi: [10.1088/1741-2560/5/1/008](https://doi.org/10.1088/1741-2560/5/1/008)\n",
    "\n",
    "<br>\n",
    "\n",
    "From the dataset readme:\n",
    "\n",
    "*During the study, each patient was in a semi-recumbent position in a hospital bed about 1 m from a computer monitor. The patient used a joystick to maneuver a white cursor track a green target moving counter-clockwise in a circle of diameter 85% of monitor height ~1m away. The hand used to control the joystick was contralateral to the implanted electrode array.*\n",
    "\n",
    "<br>\n",
    "\n",
    "We also know that subject 0 was implanted in the left temporal lobe, while subject 2 was implanted in the right frontal lobe.\n",
    "\n",
    "Sample rate is always 1000Hz, and the ECoG data has been notch-filtered at 60, 120, 180, 240 and 250Hz, followed by z-scoring across the entire recording and conversion to float16 to minimize size.\n",
    "\n",
    "Variables are:\n",
    "* `dat['V']`: continuous voltage data (time by channels)\n",
    "* `dat['targetX']`: position of the target on the screen\n",
    "* `dat['targetY']`: position of the target on the screen\n",
    "* `dat['cursorX']`: X position of the cursor controlled by the joystick\n",
    "* `dat['cursorY']`: X position of the cursor controlled by the joystick\n",
    "* `dat['locs`]: three-dimensional coordinates of the electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8821c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "from nimare import utils\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "locs = dat['locs']\n",
    "view = plotting.view_markers(utils.tal2mni(locs),\n",
    "                             marker_labels=['%d'%k for k in np.arange(locs.shape[0])],\n",
    "                             marker_color='purple',\n",
    "                             marker_size=5)\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlations between voltage data and X/Y position of cursor\n",
    "from scipy import signal\n",
    "dat = alldat[0][3]\n",
    "\n",
    "V = dat['V'].astype('float32')\n",
    "\n",
    "nt, nchan = V.shape\n",
    "\n",
    "targetX = dat['targetX'].flatten()\n",
    "targetY = dat['targetY'].flatten()\n",
    "\n",
    "cx = np.zeros(nchan, )\n",
    "cy = np.zeros(nchan, )\n",
    "for j in range(nchan):\n",
    "    cx[j] = np.corrcoef(V[:, j], targetX)[0, 1]\n",
    "    cy[j] = np.corrcoef(V[:, j], targetY)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2869c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 4, 1)\n",
    "plt.plot(cx)\n",
    "plt.plot(cy)\n",
    "plt.ylabel('correlation with\\n X / Y position of cursor')\n",
    "plt.xlabel('channel index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3903c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one needs a lot more plots!\n",
    "# for some reason, I only see meaningful correlations in subjects 2 and 3,\n",
    "# but it's possible that there is spectral information that is more useful in those subjects"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
